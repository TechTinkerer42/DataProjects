{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction:-Time-Series-Forecasting-Project\" data-toc-modified-id=\"Introduction:-Time-Series-Forecasting-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction: Time Series Forecasting Project</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Dataset</a></span></li><li><span><a href=\"#Python-Library\" data-toc-modified-id=\"Python-Library-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Python Library</a></span></li></ul></li><li><span><a href=\"#Exploratory-Data-Loading\" data-toc-modified-id=\"Exploratory-Data-Loading-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Exploratory Data Loading</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-In-Data-From-csv-Files\" data-toc-modified-id=\"Read-In-Data-From-csv-Files-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Read In Data From csv Files</a></span></li><li><span><a href=\"#Distribution-and-Trending-of-Sales-Data\" data-toc-modified-id=\"Distribution-and-Trending-of-Sales-Data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Distribution and Trending of Sales Data</a></span></li></ul></li><li><span><a href=\"#Time-Series-Analytics-with-Four-Approaches\" data-toc-modified-id=\"Time-Series-Analytics-with-Four-Approaches-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Time Series Analytics with Four Approaches</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup-Metrics\" data-toc-modified-id=\"Setup-Metrics-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Setup Metrics</a></span></li><li><span><a href=\"#Setup-Baseline\" data-toc-modified-id=\"Setup-Baseline-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Setup Baseline</a></span></li><li><span><a href=\"#Setup-Training-and-Testing-DataSets\" data-toc-modified-id=\"Setup-Training-and-Testing-DataSets-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Setup Training and Testing DataSets</a></span></li><li><span><a href=\"#Seasonal-Autoregressive-Integrated-Moving-Average-(SARIMA)\" data-toc-modified-id=\"Seasonal-Autoregressive-Integrated-Moving-Average-(SARIMA)-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Seasonal Autoregressive Integrated Moving Average (SARIMA)</a></span></li><li><span><a href=\"#Autoregressive-Integrated-Moving-Average-(ARIMA)\" data-toc-modified-id=\"Autoregressive-Integrated-Moving-Average-(ARIMA)-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Autoregressive Integrated Moving Average (ARIMA)</a></span></li><li><span><a href=\"#Exponential-Smoothing\" data-toc-modified-id=\"Exponential-Smoothing-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Exponential Smoothing</a></span></li><li><span><a href=\"#Facebook-Prophet\" data-toc-modified-id=\"Facebook-Prophet-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Facebook Prophet</a></span></li><li><span><a href=\"#Visual-Comparison-of-Time-Series-Approaches\" data-toc-modified-id=\"Visual-Comparison-of-Time-Series-Approaches-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Visual Comparison of Time Series Approaches</a></span></li></ul></li><li><span><a href=\"#Forecasting-based-on-Two-Different-Trending-Patterns\" data-toc-modified-id=\"Forecasting-based-on-Two-Different-Trending-Patterns-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Forecasting based on Two Different Trending Patterns</a></span><ul class=\"toc-item\"><li><span><a href=\"#Separate-DataSets-based-on-Two-Trending-Patterns\" data-toc-modified-id=\"Separate-DataSets-based-on-Two-Trending-Patterns-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Separate DataSets based on Two Trending Patterns</a></span></li><li><span><a href=\"#Forecasting-for-Period-of-1/1/2013---12/1/2016\" data-toc-modified-id=\"Forecasting-for-Period-of-1/1/2013---12/1/2016-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Forecasting for Period of 1/1/2013 - 12/1/2016</a></span></li><li><span><a href=\"#Forecasting-for-Period-of-1/1/2017---10/1/2018\" data-toc-modified-id=\"Forecasting-for-Period-of-1/1/2017---10/1/2018-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Forecasting for Period of 1/1/2017 - 10/1/2018</a></span></li></ul></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Conclusions</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Time Series Forecasting Project\n",
    "\n",
    "In this notebook, I will demonstrate how to implement a time series forecasting project based on a historical dataset of sales.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset is a historical data of sales stored at [datasets](../datasets/forecasting_data_RAV4_sales.csv) folder.\n",
    "\n",
    "## Python Library\n",
    "\n",
    "I will use Python library __pandas__ & __numpy__ to read-in and process the data from a local machine, __matplotlib__ & __seaborn__ to visualize the data and forecasting results, __statmodels__ and __fbprophet__ for time series forecasting approaches. For the approaches, I will examine and evaluate __Seasonal AutoRegression Integrated Moving Average (SARIMA)__, __AutoRegression Integrated Moving Average (ARIMA)__, __Exponential Smoothing__ and __Facebook Prophet__ approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:37.904852Z",
     "start_time": "2019-08-28T01:42:36.296554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas and numpy for data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pandas.tseries.offsets import MonthEnd\n",
    "# Make the random numbers predictable\n",
    "np.random.seed(42)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:40.372155Z",
     "start_time": "2019-08-28T01:42:37.908451Z"
    }
   },
   "outputs": [],
   "source": [
    "# Time Series Models\n",
    "# import FB Prophet\n",
    "from fbprophet import Prophet\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:40.433159Z",
     "start_time": "2019-08-28T01:42:40.374780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matplotlib and seaborn for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up matplotlib environment\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "matplotlib.rcParams['figure.figsize'] = (18, 18)\n",
    "\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In Data From csv Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:40.470155Z",
     "start_time": "2019-08-28T01:42:40.434935Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1/1/2013</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-01</th>\n",
       "      <td>2/1/2013</td>\n",
       "      <td>2081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-01</th>\n",
       "      <td>3/1/2013</td>\n",
       "      <td>2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-01</th>\n",
       "      <td>4/1/2013</td>\n",
       "      <td>2657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>5/1/2013</td>\n",
       "      <td>2726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01</th>\n",
       "      <td>6/1/2013</td>\n",
       "      <td>2716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7/1/2013</td>\n",
       "      <td>3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-01</th>\n",
       "      <td>8/1/2013</td>\n",
       "      <td>3302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-01</th>\n",
       "      <td>9/1/2013</td>\n",
       "      <td>3243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>10/1/2013</td>\n",
       "      <td>3549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds     y\n",
       "ds                         \n",
       "2013-01-01   1/1/2013  2399\n",
       "2013-02-01   2/1/2013  2081\n",
       "2013-03-01   3/1/2013  2395\n",
       "2013-04-01   4/1/2013  2657\n",
       "2013-05-01   5/1/2013  2726\n",
       "2013-06-01   6/1/2013  2716\n",
       "2013-07-01   7/1/2013  3194\n",
       "2013-08-01   8/1/2013  3302\n",
       "2013-09-01   9/1/2013  3243\n",
       "2013-10-01  10/1/2013  3549"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read three data sets\n",
    "# need a different encoding rather than the default utf-8 \n",
    "# due to some specific letters in the data sets\n",
    "df = pd.read_csv('../datasets/forecasting_data_RAV4_sales.csv')\n",
    "df = df.loc[(df['sales'] >0), ['Month', 'sales']]\n",
    "df.rename(columns={'Month':'ds', 'sales':'y'}, inplace=True)\n",
    "df.index = pd.to_datetime(df.ds)\n",
    "df.sort_index(inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution and Trending of Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.077323Z",
     "start_time": "2019-08-28T01:42:40.472053Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Trending plot of sales\n",
    "plt.plot(df.index, df['y'].values, color='blue', linestyle='-')\n",
    "plt.plot([df.index[0], df.index[-1]], [df['y'].values[0], df['y'].values[-1]], label='trend', color='red', linestyle='--')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Sales History')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.080829Z",
     "start_time": "2019-08-28T01:42:36.752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bar plot of sales\n",
    "plt.bar(df.index, df['y'].values, fill = 'blue', edgecolor = 'b', width = 3)\n",
    "plt.plot([df.index[0], df.index[-1]], [df['y'].values[0], df['y'].values[-1]], label='trend', color='red', linestyle='--')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Distribution of sales')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analytics with Four Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Metrics\n",
    "\n",
    "For this analytics project, I will use two standard metrics (wiki definitions) from :\n",
    "\n",
    "* Mean Absolute Error (MAE): is an interpretable & scale-dependent accuracy measure of difference between two continuous variables and is average vertical distance between each point and the identity line.\n",
    "* Root Mean Squared Error (RMSE): is a frequently used & scale-dependent measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed. It represents the square root of the second sample moment of the differences between predicted values and observed values or the quadratic mean of these differences. RMSE is always non-negative, and a value of 0 (almost never achieved in practice) would indicate a perfect fit to the data. In general, a lower RMSE is better than a higher one.\n",
    "\n",
    "For more information and discussions around those two metrices, [here is a discussion](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Baseline\n",
    "\n",
    "For a time series forecasting approach, a simple baseline is to guess the median value on the training set for all testing cases. I will evaluate if forecasting approach can be better than the simple baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.082133Z",
     "start_time": "2019-08-28T01:42:37.255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline is the median\n",
    "baseline_pred = df['y'].median()\n",
    "baseline_preds = [baseline_pred for _ in range(len(df))]\n",
    "real = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.083325Z",
     "start_time": "2019-08-28T01:42:37.258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate mae and rmse\n",
    "def evaluate_predictions(predictions, real):\n",
    "    mae = np.mean(abs(predictions - real))\n",
    "    rmse = np.sqrt(np.mean((predictions - real) ** 2))    \n",
    "    return mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.085080Z",
     "start_time": "2019-08-28T01:42:37.260Z"
    }
   },
   "outputs": [],
   "source": [
    "mb_MAE, mb_RMSE = evaluate_predictions(baseline_preds, real)\n",
    "print('Baseline  MAE: {:.4f}'.format(mb_MAE))\n",
    "print('Baseline RMSE: {:.4f}'.format(mb_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training and Testing DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.087639Z",
     "start_time": "2019-08-28T01:42:37.422Z"
    }
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('../datasets/forecasting_data_RAV4_sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=None)\n",
    "# print(series)\n",
    "X = series.values\n",
    "size = int(len(X) * 0.70)\n",
    "train, test = X[0:size], X[size:len(X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Autoregressive Integrated Moving Average (SARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMA models are a general time series model, and is used to analyze and forecast data which have an additional seasonal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.089547Z",
     "start_time": "2019-08-28T01:42:37.664Z"
    }
   },
   "outputs": [],
   "source": [
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "    model = SARIMAX(history, seasonal_order=(0,0,0,12), enforce_stationarity=False)\n",
    "    model_fit = model.fit()\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "    print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "SARIMA_RMSE = np.sqrt(mean_squared_error(test, predictions))\n",
    "SARIMA_MAE = mean_absolute_error(test, predictions)\n",
    "print('Test MAE: %.3f' % SARIMA_MAE)\n",
    "print('Test RMSE: %.3f' % SARIMA_RMSE)\n",
    "# plot\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive Integrated Moving Average (ARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a class of model that captures a suite of different standard temporal structures in time series data. It explicitly caters to a suite of standard structures in time series data, and as such provides a simple yet powerful method for making skillful time series forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.091655Z",
     "start_time": "2019-08-28T01:42:37.920Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "    model = ARIMA(history, order=(5,1,0))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "    print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "ARIMA_RMSE = np.sqrt(mean_squared_error(test, predictions))\n",
    "ARIMA_MAE = mean_absolute_error(test, predictions)\n",
    "print('Test MAE: %.3f' % ARIMA_MAE)\n",
    "print('Test RMSE: %.3f' % ARIMA_RMSE)\n",
    "# plot\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential smoothing is a time series forecasting method for univariate data. It is similar in that a prediction is a weighted sum of past observations, but the model explicitly uses an exponentially decreasing weight for past observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.093146Z",
     "start_time": "2019-08-28T01:42:38.165Z"
    }
   },
   "outputs": [],
   "source": [
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "    model = ExponentialSmoothing(history)\n",
    "    model_fit = model.fit()\n",
    "    output = model_fit.predict()\n",
    "    yhat = output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "    print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "ES_RMSE = np.sqrt(mean_squared_error(test, predictions))\n",
    "ES_MAE = mean_absolute_error(test, predictions)\n",
    "print('Test MAE: %.3f' % ES_MAE)\n",
    "print('Test RMSE: %.3f' % ES_RMSE)\n",
    "# plot\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet is designed for analyzing time series with daily observations that display patterns on different time scales. It also has advanced capabilities for modeling the effects of holidays on a time-series and implementing custom change points, but I will stick to the basic functions to get a model up and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.095197Z",
     "start_time": "2019-08-28T01:42:38.409Z"
    }
   },
   "outputs": [],
   "source": [
    "m = Prophet(yearly_seasonality=True)\n",
    "m.fit(df)\n",
    "future = m.make_future_dataframe(periods=365)\n",
    "# future.tail()\n",
    "forecast = m.predict(future)\n",
    "forecast.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.096645Z",
     "start_time": "2019-08-28T01:42:38.412Z"
    }
   },
   "outputs": [],
   "source": [
    "m.plot(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The black dots represent the actual values, the blue line indicates the forecasted values, and the light blue shaded region is the uncertainty (always a critical part of any prediction). The region of uncertainty increases the further out in the future the prediction is made because initial uncertainty propagates and grows over time. This is observed in weather forecasts which get less accurate the further out in time they are made.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, I will show that Prophet allows us to easily visualize the overall trend and the component patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.098160Z",
     "start_time": "2019-08-28T01:42:38.670Z"
    }
   },
   "outputs": [],
   "source": [
    "m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.099858Z",
     "start_time": "2019-08-28T01:42:38.673Z"
    }
   },
   "outputs": [],
   "source": [
    "forecast.index = pd.to_datetime(forecast.ds)\n",
    "forecast.sort_index(inplace=True)\n",
    "Prophet_MAE, Prophet_RMSE = evaluate_predictions(forecast['yhat'][:len(real)], real)\n",
    "print('Prophet  MAE: {:.4f}'.format(Prophet_MAE))\n",
    "print('Prophet RMSE: {:.4f}'.format(Prophet_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.101749Z",
     "start_time": "2019-08-28T01:42:38.676Z"
    }
   },
   "outputs": [],
   "source": [
    "# save forecasted 1-year results into a csv file\n",
    "results = forecast.loc[forecast['ds'] >= '2018-10-1', ['ds', 'yhat']]\n",
    "results.to_csv('forecasted_data_RAV4_sales.csv', sep=',', line_terminator='\\n', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Comparison of Time Series Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.104050Z",
     "start_time": "2019-08-28T01:42:38.895Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate forecasting approaches\n",
    "model_name_list = ['SARIMA', 'ARIMA', 'Exponential Smoothing', 'Facebook Prophet', 'Baseline']\n",
    "# Create a dataframe for results\n",
    "results = pd.DataFrame(columns=['MAE', 'RMSE'], index = model_name_list)\n",
    "\n",
    "# fill dataframe for results\n",
    "results.loc['Baseline', :] = [mb_MAE, mb_RMSE]\n",
    "results.loc['SARIMA', :] = [SARIMA_MAE, SARIMA_RMSE]\n",
    "results.loc['ARIMA', :] = [ARIMA_MAE, ARIMA_RMSE]\n",
    "results.loc['Exponential Smoothing', :] = [ES_MAE, ES_RMSE]\n",
    "results.loc['Facebook Prophet', :] = [Prophet_MAE, Prophet_RMSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.106911Z",
     "start_time": "2019-08-28T01:42:38.898Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing the evaluation results\n",
    "figsize(12, 8)\n",
    "matplotlib.rcParams['font.size'] = 16\n",
    "\n",
    "# MAE plot\n",
    "ax =  plt.subplot(1, 2, 1)\n",
    "results.sort_values('MAE', ascending = False).plot.bar(y = 'MAE', color = 'navy', ax = ax)\n",
    "plt.title('Mean Absolute Error')\n",
    "plt.ylabel('MAE')\n",
    "\n",
    "# RMSE plot\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "results.sort_values('RMSE', ascending = False).plot.bar(y = 'RMSE', color = 'g', ax = ax)\n",
    "plt.title('Root Mean Squared Error')\n",
    "plt.ylabel('RMSE')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.110696Z",
     "start_time": "2019-08-28T01:42:38.901Z"
    }
   },
   "outputs": [],
   "source": [
    "# show quantitative results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting based on Two Different Trending Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on simple observation from the historical dataset, we can easily see there are two different trending patterns: \n",
    "* one is from 1/1/2013 to 12/1/2016, \n",
    "* the other is from 1/1/2017 to 10/1/2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate DataSets based on Two Trending Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.112085Z",
     "start_time": "2019-08-28T01:42:39.309Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df[0:48]\n",
    "df2 = df[48:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting for Period of 1/1/2013 - 12/1/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.114473Z",
     "start_time": "2019-08-28T01:42:39.493Z"
    }
   },
   "outputs": [],
   "source": [
    "m1 = Prophet(yearly_seasonality=True)\n",
    "m1.fit(df1)\n",
    "future1 = m1.make_future_dataframe(periods=720)\n",
    "# future.tail()\n",
    "forecast1 = m1.predict(future1)\n",
    "m1.plot(forecast1[:len(df1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.116522Z",
     "start_time": "2019-08-28T01:42:39.496Z"
    }
   },
   "outputs": [],
   "source": [
    "real1 = df1['y']\n",
    "forecast1.index = pd.to_datetime(forecast1.ds)\n",
    "forecast1.sort_index(inplace=True)\n",
    "df_forecast1 = forecast1.loc[(forecast1['yhat'] >0), ['yhat']]\n",
    "Prophet_MAE, Prophet_RMSE = evaluate_predictions(df_forecast1['yhat'][:len(real1)], real1)\n",
    "print('Prophet  MAE: {:.4f}'.format(Prophet_MAE))\n",
    "print('Prophet RMSE: {:.4f}'.format(Prophet_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting for Period of 1/1/2017 - 10/1/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.120777Z",
     "start_time": "2019-08-28T01:42:39.634Z"
    }
   },
   "outputs": [],
   "source": [
    "m2 = Prophet(yearly_seasonality=True)\n",
    "m2.fit(df2)\n",
    "future2 = m2.make_future_dataframe(periods=365)\n",
    "# future.tail()\n",
    "forecast2 = m2.predict(future2)\n",
    "m2.plot(forecast2[:len(df2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T01:42:41.128625Z",
     "start_time": "2019-08-28T01:42:39.636Z"
    }
   },
   "outputs": [],
   "source": [
    "# real2 = df2['y'].reset_index(drop=True)\n",
    "real2 = df2['y']\n",
    "forecast2.index = pd.to_datetime(forecast2.ds)\n",
    "forecast2.sort_index(inplace=True)\n",
    "df_forecast2 = forecast2.loc[(forecast2['yhat'] >0), ['yhat']]\n",
    "Prophet_MAE, Prophet_RMSE = evaluate_predictions(df_forecast2['yhat'][:len(real2)], real2)\n",
    "print('Prophet  MAE: {:.4f}'.format(Prophet_MAE))\n",
    "print('Prophet RMSE: {:.4f}'.format(Prophet_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this notebook I went through major steps to demonstrate how a time series forecasting project was implemented with a historical data of sales. A visual comparison of four different approaches was given. Additionally, we tried the forecasting based on two different trending data by slicing the data set into two periods. The final results presented the improved RMSEs."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
